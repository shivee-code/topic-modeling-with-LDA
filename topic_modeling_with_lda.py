# -*- coding: utf-8 -*-
"""Topic Modeling with LDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LZoW5gzBVaytkDeb7-xU8Z8iAu-2tvO9
"""

!pip install --upgrade gensim scipy

import nltk
import gensim
from gensim import corpora
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string
import pandas as pd

# Download necessary resources
nltk.download('punkt_tab')
nltk.download('stopwords')

# Sample diverse corpus with different topics
documents = [
    "Python programming is used for web development and data analysis.",
    "Data science involves statistics, machine learning, and data mining.",
    "Soccer is a popular sport played worldwide, with teams in many countries.",
    "The stock market fluctuates with the economy and government policies.",
    "Healthy eating includes vegetables, fruits, and whole grains.",
    "The tech industry is constantly evolving with new advancements in AI and cloud computing.",
    "Running and swimming are good cardiovascular exercises.",
    "Apple's iPhone is one of the leading smartphones in the world.",
    "Football matches attract millions of viewers on television.",
    "AI algorithms are being use to automate tasks in various industries."
]

# Preprocessing the documents
stop_words = set(stopwords.words('english'))

def preprocessing(text):
  # Tokenizing and converting to lower case
  tokens = word_tokenize(text.lower())

  # Removing punctuation and stopwords
  tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]

  return tokens

# Preprocess all documents
processed_docs = [preprocessing(doc) for doc in documents]

processed_docs

# Create dictionary
dictionary = corpora.Dictionary(processed_docs)

# Create a corpus: a list of Bag of Words (BoW)
corpus = [dictionary.doc2bow(doc) for doc in processed_docs]

corpus

# Create the LDA model
lda_model = gensim.models.LdaMulticore(corpus, num_topics=3, id2word=dictionary, passes=15)

# Get the topics discovered by LDA and make them more readable
topics = lda_model.print_topics(num_words=5)   # You can change num_words to show more or fewer words words per topic

topics

# Organize the topics into a more readable table
topic_words = []
for topic in topics:
  topic_num, words = topic
  words = [word.split("*") for word in words.split(" + ")]
  words = [(float(weight), word.strip().strip('"')) for weight, word in words]
  topic_words.append({"Topic": topic_num, "Words": words})

topic_words

# Display topics as a DataFrame for better readability
topics_df = pd.DataFrame(topic_words)

topics_df

# Assign topic titles based on the most frequent words in the topic
def get_topic_title(topic_words):
  topic_keywords = [word for _, word in topic_words]
  if 'python' in topic_keywords or 'programming' in topic_keywords:
    return "Programming & Data Science"
  elif 'soccer' in topic_keywords or 'football' in topic_keywords:
    return "Sports (Football/Soccer)"
  elif 'ai' in topic_keywords or 'cloud' in topic_keywords:
    return "Technology & AI"
  else:
    return "General"

# Add titles for each topic
topics_df['Topic Title'] = topics_df['Words'].apply(get_topic_title)

# Print the topics and their most important words
for idx, row in topics_df.iterrows():
  print(f"Topic {row['Topic']} - {row['Topic Title']}:")
  for weight, word in row['Words']:
    print(f"  - {word} (weight: {weight:.4f})")
  print("\n")

!pip install pyLDAvis

!pip install --upgrade pyLDAvis gensim

import pyLDAvis.gensim     # Import directly from pyLDAis
import pyLDAvis

# vis = pyLDAis. gensim_models.prepare(lda_model, corpus, dictionary)
vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)
pyLDAvis.save_html(vis, 'lda_visualization.html')

# Vizualization with pyLDAvis
from google.colab import files
files.download('lda_visualization.html')

